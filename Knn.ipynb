{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import getopt\n",
    "import os\n",
    "import random\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import feature_extraction\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    X = df.values.copy()\n",
    "    np.random.seed(seed=2015)\n",
    "    np.random.shuffle(X)\n",
    "    X, labels, ids = X[:, 1:-1].astype(np.float32), X[:, -1], X[:, 0].astype(str)\n",
    "    binarizer = LabelBinarizer()\n",
    "    y = binarizer.fit_transform(labels)\n",
    "    encoder = LabelEncoder()\n",
    "    y_coded = encoder.fit_transform(labels).astype(np.int32)\n",
    "    return X, y, y_coded, ids\n",
    "    \n",
    "def load_test_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    X = df.values.copy()\n",
    "    X, ids = X[:, 1:].astype(np.float32), X[:, 0].astype(str)\n",
    "    return X, ids\n",
    "\n",
    "def transform_data(X, X_test):\n",
    "    X_all = np.vstack((X,X_test))\n",
    "    X_all = 2.*np.sqrt(X_all + (3./8.))\n",
    "    return X_all[0:X.shape[0],:], X_all[X.shape[0]:,:]\n",
    "\n",
    "def train_class(X, y, X_test, i):\n",
    "    index_shuffle = [j for j in range(X.shape[0])]\n",
    "    random.shuffle(index_shuffle)\n",
    "    yi = [t[i] for t in y[index_shuffle]]\n",
    "            \n",
    "    clf=KNeighborsClassifier(n_neighbors=par[1], weights='distance', p = par[0])\n",
    "    clf.fit(X[index_shuffle,:],yi)\n",
    "    preds_class = pd.DataFrame()\n",
    "    preds_class['Class_'+str(i+1)+'_knn8'] = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    return preds_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing iteration 0\n"
     ]
    }
   ],
   "source": [
    "train_file = './data/train.csv'\n",
    "test_file = './data/test.csv'\n",
    "pred_file = './data/sampleSubmission.csv'\n",
    "cv = 0\n",
    "nfolds = 10\n",
    "target_col = 'target'\n",
    "\n",
    "if cv == 0: \n",
    "    nfolds = 2\n",
    "\n",
    "X, y, y_coded, ids_train = load_train_data(train_file)\n",
    "X_test, ids_test = load_test_data(test_file)\n",
    "X, X_test = transform_data(X, X_test)\n",
    "num_classes = len(y[0])\n",
    "num_features = X.shape[1]\n",
    "skf = StratifiedKFold(y_coded, nfolds, random_state=2015)\n",
    "ids_train_folds = np.empty(0)\n",
    "for train_index, valid_index in skf:\n",
    "    ids_train_folds = np.append(ids_train_folds, ids_train[valid_index])\n",
    "\n",
    "#train = train.reindex(np.random.permutation(train.index))\n",
    "pars = [[2,5], [2,20], [2,40], [2,60], [2,80], [2,100], [1,5], [1,20], [1,50], [1,100], [1,70]]\n",
    "epoch = len(pars)\n",
    "\n",
    "for e in range(epoch):\n",
    "    print \"processing iteration\", e\n",
    "    #seed = random.randint(10, 1000000) + e\n",
    "    seed = 1105 + 20*e\n",
    "    par = pars[e]\n",
    "\n",
    "    if cv == 0:\n",
    "        for i in range(num_classes):\n",
    "            preds_class = train_class(X, y, X_test, i)\n",
    "            if i == 0:\n",
    "                preds_epoch = preds_class.copy()\n",
    "            else:\n",
    "                preds_epoch = pd.concat([preds_epoch, preds_class], axis = 1)\n",
    "        # parallel version\n",
    "        #list_result = Parallel(n_jobs=6)(delayed(train_class)(X, y, X_test, i) for i in range(num_classes))\n",
    "        #preds_epoch = pd.concat(list_result, axis = 1)\n",
    "    else:\n",
    "        count = 0\n",
    "        for train_index, valid_index in skf:\n",
    "            print \"processing fold\", count+1\n",
    "            X_train, X_valid = X[train_index], X[valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "            if count == 0:\n",
    "                actual = y_valid\n",
    "            else:\n",
    "                actual = np.append(actual, y_valid, axis=0)\n",
    "\n",
    "            for i in range(num_classes):\n",
    "                preds_class = train_class(X_train, y_train, X_valid, i)\n",
    "                if i == 0:\n",
    "                    preds_fold = preds_class.copy()\n",
    "                else:\n",
    "                    preds_fold = pd.concat([preds_fold, preds_class], axis = 1)\n",
    "            \n",
    "            # parallel version\n",
    "            #list_result = Parallel(n_jobs=6)(delayed(train_class)(X_train, y_train, X_valid, i) for i in range(num_classes))\n",
    "            #preds_fold = pd.concat(list_result, axis = 1)\n",
    "              \n",
    "            if count == 0:\n",
    "                preds_epoch = preds_fold.copy()\n",
    "            else:\n",
    "                preds_epoch = preds_epoch.append(preds_fold, ignore_index=True)\n",
    "\n",
    "            count += 1\n",
    "            print \"logloss\", log_loss(actual, preds_epoch.as_matrix())\n",
    "    if cv == 0:\n",
    "        preds_epoch['id'] = ids_test.astype(float).astype(int)\n",
    "        preds_epoch.to_csv('./data/output-knn/' + os.path.splitext(pred_file)[0] + '.epoch' + str(e) + '.csv', index=False)\n",
    "        preds_epoch = preds_epoch.drop('id', axis=1)\n",
    "    else:\n",
    "        preds_epoch['id'] = ids_train_folds.astype(float).astype(int)\n",
    "        preds_epoch.to_csv('./data/output-knn/' + os.path.splitext(pred_file)[0] + '.epoch' + str(e) + '.csv', index=False)\n",
    "        preds_epoch = preds_epoch.drop('id', axis=1)\n",
    "    \n",
    "    if e == 0:\n",
    "        preds = preds_epoch.copy()\n",
    "    else:\n",
    "        preds = preds.add(preds_epoch, fill_value=0)\n",
    "    if cv == 1:\n",
    "        preds_epoch = preds.copy()\n",
    "        preds_epoch = preds_epoch.divide(e+1)\n",
    "        print \"final logloss\", log_loss(actual, preds_epoch.as_matrix())\n",
    "\n",
    "        \n",
    "# create submission file\n",
    "preds = preds.divide(epoch)\n",
    "if cv == 0:\n",
    "    preds['id'] = ids_test.astype(float).astype(int)\n",
    "    preds.to_csv(os.path.splitext(pred_file)[0] + '.csv', index=False)\n",
    "else:\n",
    "    preds['id'] = ids_train_folds.astype(float).astype(int)\n",
    "    preds.to_csv(os.path.splitext(pred_file)[0] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
