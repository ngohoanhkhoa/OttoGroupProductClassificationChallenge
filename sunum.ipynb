{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries\n",
    "-------------------\n",
    "In this project we need to import some libraries as **pandas,sklearn**,etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data\n",
    "-------------------\n",
    "We can easly handle data import task with **pandas** library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
      "0   1       1       0       0       0       0       0       0       0       0   \n",
      "1   2       0       0       0       0       0       0       0       1       0   \n",
      "2   3       0       0       0       0       0       0       0       1       0   \n",
      "3   4       1       0       0       1       6       1       5       0       0   \n",
      "4   5       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "    ...     feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n",
      "0   ...           1        0        0        0        0        0        0   \n",
      "1   ...           0        0        0        0        0        0        0   \n",
      "2   ...           0        0        0        0        0        0        0   \n",
      "3   ...           0        1        2        0        0        0        0   \n",
      "4   ...           1        0        0        0        0        1        0   \n",
      "\n",
      "   feat_92  feat_93   target  \n",
      "0        0        0  Class_1  \n",
      "1        0        0  Class_1  \n",
      "2        0        0  Class_1  \n",
      "3        0        0  Class_1  \n",
      "4        0        0  Class_1  \n",
      "\n",
      "[5 rows x 95 columns]\n",
      "(61878, 93)\n",
      "(61878,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "print(df.head())\n",
    "\n",
    "X = df.drop('id', axis=1).drop('target',axis=1).values\n",
    "y = df['target'].values\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action!\n",
    "---\n",
    "#### First Try:\n",
    "prediction for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value of DecisionTreeClassifier: 0.000000\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X, y)\n",
    "tree_preds = clf.predict_proba(X)\n",
    "print(\"Loss Value of DecisionTreeClassifier: %f\" % log_loss(y, tree_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Try:\n",
    "how noise is changing loss value (again for train data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value of DecisionTreeClassifier: 0.000022\n",
      "[ 0.5  0.   0.   0.   0.   0.   0.   0.   0.5]\n",
      "Class_1\n"
     ]
    }
   ],
   "source": [
    "df_noise = pd.read_csv('train_noise.csv')\n",
    "\n",
    "X_noise = df_noise.drop('id', axis=1).drop('target',axis=1).values\n",
    "y_noise = df_noise['target'].values\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_noise, y_noise)\n",
    "tree_preds_noise = clf.predict_proba(X_noise)\n",
    "print(\"Loss Value of DecisionTreeClassifier: %f\" % log_loss(y_noise, tree_preds_noise))\n",
    "print(tree_preds_noise[-1])\n",
    "print(y_noise[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third try:\n",
    "serious one! evaluation decision tree classifier with default parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value of DecisionTreeClassifier: -9.89 (+/- 0.30)\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "scores = cross_val_score(clf,X ,y , cv=5, scoring='neg_log_loss')\n",
    "print(\"Loss Value of DecisionTreeClassifier: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ...new try:\n",
    "as we have already seen above, overfitting occurs.\n",
    "   >tuning maximum number of features (default is **None**, so... n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value of DecisionTreeClassifier: -9.98 (+/- 0.31)\n",
      "Loss Value of DecisionTreeClassifier: -10.08 (+/- 0.20)\n",
      "Loss Value of DecisionTreeClassifier: -9.97 (+/- 0.27)\n",
      "Loss Value of DecisionTreeClassifier: -9.94 (+/- 0.25)\n",
      "Loss Value of DecisionTreeClassifier: -9.93 (+/- 0.42)\n",
      "Loss Value of DecisionTreeClassifier: -9.92 (+/- 0.14)\n",
      "Loss Value of DecisionTreeClassifier: -9.91 (+/- 0.20)\n",
      "Loss Value of DecisionTreeClassifier: -10.04 (+/- 0.14)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,18):\n",
    "    clf = tree.DecisionTreeClassifier(max_features=i*5)\n",
    "    scores = cross_val_score(clf,X ,y , cv=5, scoring='neg_log_loss')\n",
    "    print(\"Loss Value of DecisionTreeClassifier: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   >tuning maximum depth of the tree (default is **None**, until all leaves are pure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value of DecisionTreeClassifier: -1.35 (+/- 0.03)\n",
      "Loss Value of DecisionTreeClassifier: -1.27 (+/- 0.03)\n",
      "Loss Value of DecisionTreeClassifier: -1.24 (+/- 0.04)\n",
      "Loss Value of DecisionTreeClassifier: -1.20 (+/- 0.04)\n",
      "Loss Value of DecisionTreeClassifier: -1.18 (+/- 0.06)\n",
      "Loss Value of DecisionTreeClassifier: -1.19 (+/- 0.07)\n",
      "Loss Value of DecisionTreeClassifier: -1.23 (+/- 0.03)\n",
      "Loss Value of DecisionTreeClassifier: -1.29 (+/- 0.06)\n",
      "Loss Value of DecisionTreeClassifier: -1.40 (+/- 0.06)\n",
      "Loss Value of DecisionTreeClassifier: -1.58 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,15):\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    scores = cross_val_score(clf,X ,y , cv=5, scoring='neg_log_loss')\n",
    "    print(\"Loss Value of DecisionTreeClassifier: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   >tuning minimum number of samples required to split (default is **2**, we split always!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value of DecisionTreeClassifier: -1.05 (+/- 0.06)\n",
      "Loss Value of DecisionTreeClassifier: -1.05 (+/- 0.06)\n",
      "Loss Value of DecisionTreeClassifier: -1.05 (+/- 0.05)\n",
      "Loss Value of DecisionTreeClassifier: -1.05 (+/- 0.06)\n",
      "Loss Value of DecisionTreeClassifier: -1.04 (+/- 0.06)\n",
      "Loss Value of DecisionTreeClassifier: -1.04 (+/- 0.05)\n",
      "Loss Value of DecisionTreeClassifier: -1.04 (+/- 0.05)\n",
      "Loss Value of DecisionTreeClassifier: -1.04 (+/- 0.05)\n",
      "Loss Value of DecisionTreeClassifier: -1.04 (+/- 0.04)\n",
      "Loss Value of DecisionTreeClassifier: -1.04 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "for i in range(80,90):\n",
    "    clf = tree.DecisionTreeClassifier(min_samples_split=i*10)\n",
    "    scores = cross_val_score(clf,X ,y , cv=5, scoring='neg_log_loss')\n",
    "    print(\"Loss Value of DecisionTreeClassifier: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   >tuning minimum number of samples required to be at a leaf node (default is **1**, everybody can be a leaf node!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value of DecisionTreeClassifier: -1.01 (+/- 0.05)\n",
      "Loss Value of DecisionTreeClassifier: -1.00 (+/- 0.02)\n",
      "Loss Value of DecisionTreeClassifier: -1.00 (+/- 0.03)\n",
      "Loss Value of DecisionTreeClassifier: -1.00 (+/- 0.02)\n",
      "Loss Value of DecisionTreeClassifier: -1.00 (+/- 0.03)\n",
      "Loss Value of DecisionTreeClassifier: -1.01 (+/- 0.03)\n",
      "Loss Value of DecisionTreeClassifier: -1.00 (+/- 0.04)\n",
      "Loss Value of DecisionTreeClassifier: -1.01 (+/- 0.04)\n",
      "Loss Value of DecisionTreeClassifier: -1.00 (+/- 0.03)\n",
      "Loss Value of DecisionTreeClassifier: -1.00 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "for i in range(18,28):\n",
    "    clf = tree.DecisionTreeClassifier(min_samples_leaf=i*10)\n",
    "    scores = cross_val_score(clf,X ,y , cv=5, scoring='neg_log_loss')\n",
    "    print(\"Loss Value of DecisionTreeClassifier: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ...time to Extra Trees+Calibrated:\n",
    "#### ...maybe Calibrated Classifier helps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value of DecisionTreeClassifier: -1.54 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=10)\n",
    "scores = cross_val_score(clf,X ,y , cv=5, scoring='neg_log_loss')\n",
    "print(\"Loss Value of DecisionTreeClassifier: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value of DecisionTreeClassifier: -0.71 (+/- 0.04)\n",
      "Loss Value of DecisionTreeClassifier: -0.71 (+/- 0.01)\n",
      "Loss Value of DecisionTreeClassifier: -0.71 (+/- 0.02)\n",
      "Loss Value of DecisionTreeClassifier: -0.71 (+/- 0.03)\n",
      "Loss Value of DecisionTreeClassifier: -0.71 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "for i in range(25,30):\n",
    "    clf = ExtraTreesClassifier(n_estimators=10,min_samples_split=i)\n",
    "    scores = cross_val_score(clf,X ,y , cv=5, scoring='neg_log_loss')\n",
    "    print(\"Loss Value of DecisionTreeClassifier: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value of DecisionTreeClassifier: -1.53 (+/- 0.07)\n",
      "Loss Value of DecisionTreeClassifier: -0.82 (+/- 0.07)\n",
      "Loss Value of DecisionTreeClassifier: -0.73 (+/- 0.03)\n",
      "Loss Value of DecisionTreeClassifier: -0.73 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    clf = ExtraTreesClassifier(n_estimators=10,min_samples_leaf=i)\n",
    "    scores = cross_val_score(clf,X ,y , cv=5, scoring='neg_log_loss')\n",
    "    print(\"Loss Value of DecisionTreeClassifier: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value of DecisionTreeClassifier: -0.83 (+/- 0.03)\n",
      "Loss Value of DecisionTreeClassifier: -0.83 (+/- 0.01)\n",
      "Loss Value of DecisionTreeClassifier: -0.81 (+/- 0.02)\n",
      "Loss Value of DecisionTreeClassifier: -0.82 (+/- 0.03)\n",
      "Loss Value of DecisionTreeClassifier: -0.81 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "for i in range(30,35):\n",
    "    clf = ExtraTreesClassifier(n_estimators=10,max_depth=i)\n",
    "    scores = cross_val_score(clf,X ,y , cv=5, scoring='neg_log_loss')\n",
    "    print(\"Loss Value of DecisionTreeClassifier: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value of DecisionTreeClassifier: -0.59 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=10)\n",
    "calibrated_clf = CalibratedClassifierCV(clf, method='isotonic')\n",
    "scores = cross_val_score(calibrated_clf,X ,y , cv=5, scoring='neg_log_loss')\n",
    "print(\"Loss Value of DecisionTreeClassifier: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value of DecisionTreeClassifier: -0.56 (+/- 0.01)\n",
      "Loss Value of DecisionTreeClassifier: -0.56 (+/- 0.01)\n",
      "Loss Value of DecisionTreeClassifier: -0.57 (+/- 0.02)\n",
      "Loss Value of DecisionTreeClassifier: -0.57 (+/- 0.01)\n",
      "Loss Value of DecisionTreeClassifier: -0.56 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "for i in range(15,20):\n",
    "    clf = ExtraTreesClassifier(n_estimators=10,min_samples_split=i)\n",
    "    calibrated_clf = CalibratedClassifierCV(clf, method='isotonic')\n",
    "    scores = cross_val_score(calibrated_clf,X ,y , cv=5, scoring='neg_log_loss')\n",
    "    print(\"Loss Value of DecisionTreeClassifier: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value of DecisionTreeClassifier: -0.48 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "calibrated_clf = CalibratedClassifierCV(clf, method='isotonic')\n",
    "scores = cross_val_score(calibrated_clf,X ,y , cv=5, scoring='neg_log_loss')\n",
    "print(\"Loss Value of DecisionTreeClassifier: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "test_data = np.genfromtxt('test.csv', delimiter=',',dtype=None)[1:]\n",
    "test_data_x = test_data[:,1:]\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=1000)\n",
    "calibrated_clf = CalibratedClassifierCV(clf, method='isotonic')\n",
    "calibrated_clf.fit(X ,y)\n",
    "cikti_x = calibrated_clf.predict_proba(test_data_x)\n",
    "\n",
    "\n",
    "with open('cikti7.csv', 'w') as csvfile:\n",
    "    fieldnames = ['id','Class_1','Class_2','Class_3','Class_4','Class_5','Class_6','Class_7','Class_8','Class_9']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    x = 1\n",
    "    for item in cikti_x:\n",
    "        #Write item to outcsv\n",
    "        writer.writerow({'id':x,'Class_1':format(round(item[0],2)), 'Class_2':format(round(item[1],2)), 'Class_3':format(round(item[2],2)),'Class_4':format(round(item[3],2)),'Class_5':format(round(item[4],2)),'Class_6':format(round(item[5],2)),'Class_7':format(round(item[6],2)),'Class_8':format(round(item[7],2)),'Class_9':format(round(item[8],2))})\n",
    "        x=x+1\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
